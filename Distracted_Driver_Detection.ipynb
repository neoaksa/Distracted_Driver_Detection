{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distracted Driver Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/neoaksa/Distracted_Driver_Detection/blob/master/Distracted_Driver_Detection.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "yRAT-5QGzzCX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Distracted Driver images are from kaggle competiton which you can find detail [here](https://www.kaggle.com/c/state-farm-distracted-driver-detection#description).\n",
        "\n",
        "Basicly, the data alrealy labeled into 10 different statues, from C0 to C9. \n",
        "- c0: normal driving\n",
        "- c1: texting - right\n",
        "- c2: talking on the phone - right\n",
        "- c3: texting - left\n",
        "- c4: talking on the phone - left\n",
        "- c5: operating the radio\n",
        "- c6: drinking\n",
        "- c7: reaching behind\n",
        "- c8: hair and makeup\n",
        "- c9: talking to passenger \n",
        "\n",
        "we know it is a supervised learning problem and there are bunch of solutions for this problem in kaggle. But I still want to implent it as I need to build a standard pipline for this kind of issue and try variety model by keras to achieve the best result basis of  multi-class logarithmic loss.   "
      ]
    },
    {
      "metadata": {
        "id": "-_MuC5hE2_r3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 1**: the first setp is simple, download the raw data from google drive and unzip the image folder. This might take a while since the image zip file are almost 4Gb. Compressed file :https://drive.google.com/file/d/1OA94GnqYDD9O4NPxepRot4-whIYYC62S/view?usp=sharing\n",
        " Plus: you will love Google componets, the uncompress process is super faster than your own pc."
      ]
    },
    {
      "metadata": {
        "id": "OAYAgTipuNON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "914e909b-04ca-4e3d-fd7c-60a04ac56978"
      },
      "cell_type": "code",
      "source": [
        "! pip install pydrive\n",
        "# these classes allow you to request the Google drive API\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab import auth\n",
        "import zipfile\n",
        "\n",
        "# authenticate google drive\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def downloadFile(inputfilename,outputfilename):\n",
        "    downloaded = drive.CreateFile({'id': inputfilename})\n",
        "    # assume the file is called file.csv and it's located at the root of your drive\n",
        "    downloaded.GetContentFile(outputfilename)\n",
        "    \n",
        "# traning file download\n",
        "FileObj = downloadFile(\"1OA94GnqYDD9O4NPxepRot4-whIYYC62S\",\"all.zip\")\n",
        "\n",
        "# unzip files\n",
        "zip_ref = zipfile.ZipFile('all.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()\n",
        "# unzip images\n",
        "zip_ref = zipfile.ZipFile('imgs.zip', 'r')\n",
        "zip_ref.extractall('./imgs/')\n",
        "zip_ref.close()\n",
        "\n",
        "# check the dictory\n",
        "import os\n",
        "for x in os.listdir('./'):\n",
        "    print(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\n",
            "sample_data\n",
            ".config\n",
            "all.zip\n",
            "sample_submission.csv\n",
            "imgs\n",
            "adc.json\n",
            "imgs.zip\n",
            "driver_imgs_list.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3bO69Nf9ppX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So, we got the raw data we need. \n",
        "- *driver_imgs_list.csv* is the label information. \n",
        "- *imgs* is the folder for storing images by classifications\n",
        "- *sample_submission.csv* is the submission format, we can leave it alone."
      ]
    },
    {
      "metadata": {
        "id": "STyDtd2K--7i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Before we do any data analysis, we need to overview the whole dataset, such as distribution of samples or take a peek of images by each classification."
      ]
    },
    {
      "metadata": {
        "id": "yrz29hSW-4uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "be912389-ff3a-434b-9ca5-2466baf93c61"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load data from  driver_imgs_list.csv\n",
        "df_all = pd.read_csv('driver_imgs_list.csv')\n",
        "print(df_all['classname'].value_counts())\n",
        "df_all['classname'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c0    2489\n",
            "c3    2346\n",
            "c4    2326\n",
            "c6    2325\n",
            "c2    2317\n",
            "c5    2312\n",
            "c1    2267\n",
            "c9    2129\n",
            "c7    2002\n",
            "c8    1911\n",
            "Name: classname, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd1b6126860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFLCAYAAAAZLc9xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMBbqWb92MwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd1b4077e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_Iji0V0OF7RP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The number of each category shows they are balance. Otherwise, wehave to rebalance samples by ADASYN or SMOTE."
      ]
    },
    {
      "metadata": {
        "id": "59jptpJVC4cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "89928d6a-e327-451f-d5fa-e222a60ffa9f"
      },
      "cell_type": "code",
      "source": [
        "# let's see how many samples in traing and testing folders\n",
        "print('train sample #:'+ str(sum([len(files) for r, d, files in os.walk('./imgs/train')])))\n",
        "print('test sample #:' + str(sum([len(files) for r, d, files in os.walk('./imgs/test')])))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train sample #:22424\n",
            "test sample #:79726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bqivKktJKGfC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 3**: we will use a** Convolution Neural Network** for the task. However, we don't have to build a new CNN from begining. Alternatively, we will use pre-trained ImageNet models for this task and do some transfer learning through keras."
      ]
    },
    {
      "metadata": {
        "id": "vipGVPYtWNDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as k \n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "\n",
        "img_width, img_height = 256, 256\n",
        "train_data_dir = \"data/train\"\n",
        "validation_data_dir = \"data/val\"\n",
        "nb_train_samples = 4125\n",
        "nb_validation_samples = 466 \n",
        "batch_size = 16\n",
        "epochs = 50\n",
        "\n",
        "# VGG19 model\n",
        "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
        "# Freeze the first 5 layers(Cov layers), and only train FC layer\n",
        "for layer in model.layers[:5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Adding custom Layers \n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(16, activation=\"softmax\")(x)\n",
        "\n",
        "# creating the final model \n",
        "model_final = Model(input = model.input, output = predictions)\n",
        "\n",
        "# compile the model \n",
        "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "\n",
        "# Initiate the train and test generators with data Augumentation \n",
        "train_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_data_dir,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size, \n",
        "class_mode = \"categorical\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "validation_data_dir,\n",
        "target_size = (img_height, img_width),\n",
        "class_mode = \"categorical\")\n",
        "\n",
        "# Save the model according to the conditions  \n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "# Train the model \n",
        "model_final.fit_generator(\n",
        "train_generator,\n",
        "samples_per_epoch = nb_train_samples,\n",
        "epochs = epochs,\n",
        "validation_data = validation_generator,\n",
        "nb_val_samples = nb_validation_samples,\n",
        "callbacks = [checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}